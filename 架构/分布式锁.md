如何实现分布式锁？
# 案例分析
- 基于关系型数据库 MySQL 实现分布式锁；
- 基于分布式缓存 Redis 实现分布式锁；
 基于 Redis 的 setnx 加过期时间来实现分布式锁
## 应对的问题
<strong >可用问题</strong>：无论何时都要保证锁服务的可用性。

<strong >死锁问题</strong>：客户端一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达（这是避免死锁的设计原则）。

<strong>脑裂问题</strong>：集群同步时产生的数据不一致，导致新的进程有可能拿到锁，但之前的进程以为自己还有锁，那么就出现两个进程拿到了同一个锁的问题。
## 案例解析

### 基于关系型数据库实现分布式锁
基于关系型数据库（如 MySQL）做法如下：先查询数据库是否存在记录，为了防止幻读取（幻读取：事务 A 按照一定条件进行数据读取，这期间事务 B 插入了相同搜索条件的新数据，事务 A 再次按照原先条件进行读取时，发现了事务 B 新插入的数据）通过数据库行锁 select for update 锁住这行数据，然后将查询和插入的 SQL 在同一个事务中提交。
基于关系型数据库实现分布式锁比较简单，基于 MySQL 行锁的方式会出现交叉死锁，比如事务 1 和事务 2 分别取得了记录 1 和记录 2 的排它锁，然后事务 1 又要取得记录 2 的排它锁，事务 2 也要获取记录 1 的排它锁，那这两个事务就会因为相互锁等待，产生死锁。可以通过“超时控制”解决交叉死锁的问题，但在高并发情况下，出现的大部分请求都会排队等待，所以“基于关系型数据库实现分布式锁”的方式在性能上存在缺陷，

#### 延伸问题。
-数据库的事务隔离级别
如果你想让系统支持海量并发，那数据库的并发处理能力就尤为重要，而影响数据库并发能力最重要的因素是<strong >数据库的事务隔离机制</strong>。
数据库的四种隔离级别从低到高分别是：
-读未提交（READ UNCOMMITTED）；
读已提交（READ COMMITTED）；
可重复读（REPEATABLE READ）；
可串行化（SERIALIZABLE）。
可串行化操作就是按照事务的先后顺序，排队执行，然而一个事务操作可能要执行很久才能完成，这就没有并发效率可言了，<strong data->所以数据库隔离级别越高，系统的并发性能就越差。</strong>

### 基于乐观锁的方式实现分布式锁
select for update 是悲观锁，会一直阻塞直到事务提交，所以为了不产生锁等待而消耗资源，你可以基于乐观锁的方式来实现分布式锁，比如基于版本号的方式，首先在数据库增加一个 int 型字段 ver，然后在 SELECT 同时获取 ver 值，最后在 UPDATE 的时候检查 ver 值是否为与第 2 步或得到的版本值相同。

### 基于分布式缓存实现分布式锁
在加锁的过程中，实际上就是在给 Key 键设置一个值，为避免死锁，还要给 Key 键设置一个过期时间。<code data-language="basic">SET lock_key unique_id NX PX 10000</code>
- lock_key 就是 key 键；
- unique_id 是客户端生成的唯一的标识；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

  #### 引申问题
- Redis 的超时时间设置问题；
 过短？过长？
- 站在架构设计层面上 Redis 怎么解决集群情况下分布式锁的可靠性问题。
Redis 官方已经设计了一个分布式锁算法 Redlock 解决了这个问题。Redlock 算法的基本思路，是让客户端和多个独立的 Redis Master实例依次请求申请加锁，Redlock 算法设置了加锁的超时时间，为了避免因为某个 Redis 实例发生故障而一直等待的情况，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。















